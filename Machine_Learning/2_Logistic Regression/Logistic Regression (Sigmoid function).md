## Logistic Regression using Sigmoid function

í†µê³„ì  ë¶„ë¥˜ë¥¼ ì˜í•´ linear regressionì„ ì‚¬ìš©í•˜ë©´ ëª‡ê°€ì§€ ë¬¸ì œì ì´ ë°œìƒí•œë‹¤.

- 0~1 ì™¸ì˜ yê°’ì„ ê°–ê²Œ ëœë‹¤.
- outliersì— ë¯¼ê°í•˜ê²Œ ë³€í•œë‹¤.

ìœ„ ë‘ ë¬¸ì œì ì„ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.



<img src="https://user-images.githubusercontent.com/84625523/124118730-9a20c100-daac-11eb-9f7c-d980926d68cd.png" alt="image-20210627211127811"  />

![image-20210627211042176](https://user-images.githubusercontent.com/84625523/124118759-a6a51980-daac-11eb-8f13-c6d712d4de7c.png)

ì•ì„œ ë§í–ˆë“¯ì´ 0ê³¼ 1ë¡œë§Œ êµ¬ë¶„ë˜ì–´ì•¼ í•˜ëŠ”ë° ê·¸ ì™¸ì˜ ê°’ì„ ê°–ê²Œ ëœë‹¤. 
ë˜í•œ ê°€ì¥ ì˜¤ë¥¸ìª½ì— ìˆëŠ” sampleì— ì˜í•´ regression lineì´ í¬ê²Œ ë³€í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### Sigmoid Function

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ sigmoid functionì„ ì‚¬ìš©í•œë‹¤. sigmoid functionì˜ ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.

![sigmoid function](https://user-images.githubusercontent.com/84625523/124118817-b886bc80-daac-11eb-8d3c-5be0fcfb1ab4.png)

sigmoid functionì—ì„œ e^(-x) xëŒ€ì‹  (b0 + b1 * x1 + b2 * x2 + ... bn * xn)ìœ¼ë¡œ ë°”ê¿” b0~n ê°’ì„ ê³„ì‚°í•´ì„œ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰ëœë‹¤.

sigmoid functionì˜ ì–‘ë³€ì— ìì—°ë¡œê·¸(ln)ì„ ì”Œì›Œì¤€ ê²ƒì„ logit transformationì´ë¼ê³  í•˜ê³ , ì´ë¥¼ í†µí•´ ì‹ì„ linearlizeí•  ìˆ˜ ìˆë‹¤. ì–‘ë³€ì— ìì—°ë¡œê·¸ë¥¼ ì”Œì›Œì£¼ë©´ ì•„ë˜ì™€ ê°™ì€ ì‹ì´ ëœë‹¤.

![](https://user-images.githubusercontent.com/84625523/124119400-701bce80-daad-11eb-9f29-5cba8d943c7f.gif)

ì´ì²˜ëŸ¼ í•¨ìˆ˜ì˜ ëª¨ì–‘ì´ linearí•œê²Œ ì•„ë‹ˆë¼ paramaterë“¤ì´ linearí•˜ê²Œ í‘œí˜„í•˜ëŠ” ê²ƒì„ linearlizeí•œë‹¤ ë¼ê³  í‘œí˜„í•œë‹¤.



### MLE - Maximum Likelihood Estimation

Logistic Regressionì˜ parameterë“¤ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì´ë‹¤. likelihood functionì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ì˜ˆì¸¡í•œë‹¤.

![](https://user-images.githubusercontent.com/84625523/124119800-ecaead00-daad-11eb-80b0-d9556e6ae07f.png)

ìœ„ ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ğ›½ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

![](https://user-images.githubusercontent.com/84625523/124120195-6fd00300-daae-11eb-8fba-ee0425222fc3.png)

x'ì€ x1~nì„ ì˜ë¯¸í•œë‹¤. ì´ ê°’ì€ **Newton-Raphson** methodë¡œ êµ¬í•œë‹¤.





### ì‹¤ìŠµ ì½”ë“œ_1

0. ë¼ì´ë¸ŒëŸ¬ë¦¬ import

   ```python
   import numpy as np
   from matplotlib import pyplot as plt
   from sklearn.linear_model import LogisticRegression
   ```

   

1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

   ```python
   x1 = np.array([0, 0.6, 1.1, 1.5, 1.8, 2.5, 3, 3.1, 3.9, 4, 4.9, 5, 5.1])
   y1 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
   
   x2 = np.array([3, 3.8, 4.4, 5.2, 5.5, 6.5, 6, 6.1, 6.9, 7, 7.9, 8, 8.1])
   y2 = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
   
   X = np.array([[0], [0.6], [1.1], [1.5], [1.8], [2.5], [3], [3.1], [3.9], [4], [4.9], [5], [5.1], 
                 [3], [3.8], [4.4], [5.2], [5.5], [6.5], [6], [6.1], [6.9], [7], [7.9], [8], [8.1]])
   y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
                 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
   ```

   ì´ë²ˆ ì‹¤ìŠµì€ sigmoid functionì˜ ëŒ€ëµì ì¸ ì˜ˆì‹œì´ê¸° ë•Œë¬¸ì— ì„ì˜ì˜ ìˆ«ìë¥¼ ì´ìš©í–ˆë‹¤.
   ìœ„ì—ì„œ ë§í–ˆë“¯ì´ yê°’ì€ 0 í˜¹ì€ 1ë¡œ ê³ ì •ë˜ì–´ ìˆê³  ë¶„ë¥˜ë¥¼ í•˜ê¸° ìœ„í•œ regressionì„ ì§„í•œë‹¤.



2. ëª¨ë¸ í”¼íŒ… ë° (x1, y1), (x2, y2) ê·¸ë˜í”„ í™•ì¸

   ```python
   plt.plot(x1, y1, 'bo')  # (x1, y1) as blue dot
   plt.plot(x2, y2, 'ro')  # (x2, y2) as red dot
   
   model = LogisticRegression()
   model.fit(X, y)
   plt.show()
   ```

   <ì‹¤í–‰ê²°ê³¼>
   ![image-20210627214143818](https://user-images.githubusercontent.com/84625523/124118871-ca685f80-daac-11eb-95c5-a200a7e67bc6.png)



3. b0, b1ê°’ í™•ì¸ ë° sigmoid function ì˜ˆì¸¡

   ```python
   print("b0 is : ", model.intercept_)
   print("b1 is : ", model.coef_)
   
   def logistic(classifier, x):
       return 1/(1+np.exp(-(model.intercept_ + model.coef_ * x)))
   
   for i in range(1, 120):
       plt.plot(i/10.0-2, logistic(model, i/10.0), 'go')	
   
   plt.axis([-2, 10, -0.5, 2])
   plt.show()
   ```

   - np.exp( num )ì€ numì„ ì§€ìˆ˜ë¡œ í•˜ëŠ” eì˜ ì§€ìˆ˜í•¨ìˆ˜(e^num)ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤.
   - sigmoid functionì˜ ì§€ìˆ˜ê°’ê³¼ ë§¡ê²Œ parameterë“¤ì„ ë„£ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
   - ì´í›„ forë¬¸ì„ ì´ìš©í•´ xê°’ê³¼ yê°’ì„ ê°ê° i/10.0 - 2, sigmoid functionì˜ ê²°ê³¼ê°’ìœ¼ë¡œ ë„£ì–´ plottingì„ í–ˆë‹¤. 

   - xì¶•ì€ [-2, 10], yì¶•ì€ [-0.5, 2]ì˜ ë²”ìœ„ë¥¼ ê°–ëŠ”ë‹¤

   <ì‹¤í–‰ ê²°ê³¼>
   ![image-20210627215129724](https://user-images.githubusercontent.com/84625523/124118908-d48a5e00-daac-11eb-9416-6bc8417d641d.png)



4. xê°’ì— ëŒ€í•œ ì˜ˆì¸¡ì¹˜

   ```python
   pred = model.predict_proba([[3.5]])
   print("prediction: ", pred)
   
   ## ì‹¤í–‰ ê²°ê³¼: prediction:  [[0.72860759 0.27139241]]
   ```

   - ì´ëŠ” xê°€ 3.5ì¼ ë•Œ 0ì¼ ê°€ëŠ¥ì„±ì´ ì•½ 73%, 1ì¼ ê°€ëŠ¥ì„±ì´ ì•½ 27%ì„ì„ ì˜ë¯¸í•œë‹¤.